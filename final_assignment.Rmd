---
title: "assignment"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown file

```{r albretchExample, tidy=TRUE}
options(digits=3)
albretch <- read.table("/Users/KevinMac/Desktop/Data\ analysis/DASE-master/datasets/effortEstimation/albretch.csv", sep=",",header=TRUE, stringsAsFactors=FALSE, dec = ".") #read data
summary(albretch)
```

```{r message=FALSE, warning=FALSE, tidy=TRUE}
par(mfrow=c(1,2)) #n figures per row
size_albretch <- albretch$size
effort_albretch <- albretch$effort

hist(size_albretch, col="blue", xlab='size', ylab = 'Probability', main = 'Histogram of project Size')
lines(density(size_albretch, na.rm = T, from = 0, to = max(size_albretch)))
plot(density(size_albretch))


hist(effort_albretch, col="blue")
plot(density(effort_albretch))

boxplot(size_albretch)
boxplot(effort_albretch)

# violin plots for those two variables
library(vioplot)
vioplot(size_albretch, names = '') 
title("Violin Plot of Project Size")
vioplot(effort_albretch, names = '')
title("Violin Plot of Project Effort")

par(mfrow=c(1,1))
qqnorm(size_albretch, main="Q-Q Plot of 'size'")
qqline(size_albretch, col=2, lwd=2, lty=2) #draws a line through the first and third quartiles
qqnorm(effort_albretch,  main="Q-Q Plot of 'effort'")
qqline(effort_albretch)
```
  
```{r scatterplotExample, fig.cap="Scatterplot. Relationship between size and effort", tidy=TRUE}
plot(size_albretch, effort_albretch)
```


  
```{r logExample, echo=FALSE, tidy=TRUE}
par(mfrow=c(1,2))
logsize_albretch = log(size_albretch)
hist(logsize_albretch, col="blue", xlab="log Adjusted Function Points", main="Distribution of log AFP")
logalbretch_effort = log(effort_albretch)
hist(logalbretch_effort, col="blue",xlab="Effort", main="Distribution of log Effort")
qqnorm(logsize_albretch)
qqnorm(logalbretch_effort)
```
### Split the file so that we use 2/3 of the data for training and the remaining 1/3 for testing.
### The seed for the randomiser is also set here so that someone that is interested
### in recreating this analysis could do it exactly.

```{r}
samplesize <- floor(0.66*nrow(albretch))
set.seed(012) # to make the partition reproducible
train_idx <- sample(seq_len(nrow(albretch)), size = samplesize)
albrecht_train <- albretch[train_idx, ]
albrecht_test <- albretch[-train_idx, ]
```

### Two CSV files - one for 'testing' and another for 'training' - are created
```{r}
write.csv(albrecht_train, "albrecht_train.csv")
write.csv(albrecht_test, "albrecht_test.csv")

```



```{r}
par(mfrow=c(1,1))
# transformation of variables to log-log
xtrain <- log(albrecht_train$size)
ytrain <- log(albrecht_train$effort)

lmalbrecht <- lm( ytrain ~ xtrain)
plot(xtrain, ytrain)

abline(lmalbrecht, lwd=2, col="blue")
```


### Use the test data (remaining 1/3 of the data) in order to test our model.
### The model was built using 2/3 of the data.
```{r}
b0_tel1 <- lmalbrecht$coefficients[1]
b1_tel1 <- lmalbrecht$coefficients[2]
# calculate residuals and predicted values
res <- signif(residuals(lmalbrecht), 5)

xtest <- albrecht_test$size
ytest <- albrecht_test$effort
pre_albrecht <- exp(b0_tel1+b1_tel1*log(xtest))
# plot distances between points and the regression line
plot(xtest, ytest)
curve(exp(b0_tel1+b1_tel1*log(x)), from=0, to=1600, add=TRUE, col="blue", lwd=2)
segments(xtest, ytest, xtest, pre_tel1, col="red")

```


```{r}
gm_mean = function(x, na.rm=TRUE){
  exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))}

err <- ytest - pre_albrecht  #error or residual
ae <- abs(err)
hist(ae, main="Absolute Error in the China Test data")
mar <- mean(ae)
mre <- ae/ytest
mmre <- mean(mre)
mdmre <- median(mre)
gmar <- gm_mean(ae)
mar
mmre
mdmre
gmar
```



### Here, the amount of correct data points are counted.
### A correct data point will be have its value Â±25% on the lin.reg line
```{r}
level_pred <- 0.25 #below and above (both)
lowpred <- ytest*(1-level_pred)
uppred <-  ytest*(1+level_pred)
pred  <-  pre_albrecht <= uppred & pre_albrecht >= lowpred  #pred is a vector with logical values 
Lpred <- sum(pred)/length(pred)
Lpred
```
### For 55.6% of the data points, the lin.reg. line is within 25% of the data point value.
